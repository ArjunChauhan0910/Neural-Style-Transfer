{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer : Myelin Foundry Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with importing all relevant packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining standard units\n",
    "\n",
    "* Multiple layers are used for style transfer to make the generated image capture more styled features from the styling image template. This has been found to give a better mix of style and content.\n",
    "* The mean values are the values which were used during the training of VGG19. This is important because the output is sensitive to these values.\n",
    "* All images are rescaled to 800x600 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]\n",
    "\n",
    "mean_values= np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\n",
    "image_width = 800\n",
    "image_height = 600\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vggmodel(path):\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "        \"\"\"\n",
    "        Return the weights and bias from the VGG model for a given layer.\n",
    "        \"\"\"\n",
    "        wb = vgg_layers[0][layer][0][0][2]\n",
    "        W = wb[0][0]\n",
    "        b = wb[0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "\n",
    "        return W, b\n",
    "\n",
    "    def _relu(conv2d_layer):\n",
    "        \"\"\"\n",
    "        Return the RELU function wrapped over a TensorFlow layer. Expects a\n",
    "        Conv2d layer input.\n",
    "        \"\"\"\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D + RELU layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "        \"\"\"\n",
    "        Return the AveragePooling layer.\n",
    "        \"\"\"\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Constructs the graph model.\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, image_height, image_width, channels)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Content loss function\n",
    "\n",
    "def content_loss(C,G):\n",
    "    #C is activation from set layer for content image \n",
    "    #G is activation from set layer for generated image\n",
    "    \n",
    "    #Get dimensions of Generated image for reshaping\n",
    "    m, H, W, n_C = G.get_shape().as_list()\n",
    "    \n",
    "    #unroll image to vectors for similarity matrix\n",
    "    C_tensor = tf.reshape(C,[n_C, H*W])\n",
    "    G_tensor = tf.reshape(G,[n_C, H*W]) \n",
    "    \n",
    "    #compute cost and normalise it \n",
    "    loss_content = (tf.reduce_sum(tf.square(tf.subtract(C_tensor, G_tensor))))/(4*H*W*n_C)\n",
    "\n",
    "    return loss_content\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Gram matrix computation\n",
    "\n",
    "def gram_matrix(A):\n",
    "    \n",
    "    gram = tf.matmul(A, tf.transpose(A))\n",
    "    return gram \n",
    "\n",
    "\n",
    "def layer_style_loss(S, G):\n",
    "    #S is activation from set layer for style image \n",
    "    #G is activation from set layer for generated image\n",
    "    \n",
    "    #Get dimensions of Generated image for reshaping\n",
    "    m, H, W, n_C = G.get_shape().as_list()\n",
    "    \n",
    "    #unroll image to vectors to get gram matrix computation\n",
    "    S_tensor = tf.transpose(tf.reshape(S,[ H*W,n_C]))\n",
    "    G_tensor = tf.transpose(tf.reshape(G,[ H*W,n_C]))\n",
    "    \n",
    "    #Getting gram matrices \n",
    "    S_gram = gram_matrix(S_tensor)\n",
    "    G_gram = gram_matrix(G_tensor)\n",
    "    \n",
    "    #computing cost and normalising it\n",
    "    loss_style = (tf.reduce_sum(tf.square(tf.subtract(G_gram, S_gram))))/(4*n_C**2*(H*W)**2)\n",
    "    \n",
    "    return loss_style \n",
    "    \n",
    "\n",
    "def style_loss(model, layers):\n",
    "    #Taking style across various layers with its corresponding weights\n",
    "    #which is provided by the list of ```layers```\n",
    "    \n",
    "    loss_style = 0\n",
    "    \n",
    "    for layer, coeff in layers:\n",
    "        \n",
    "        #extracting output from a particular layer\n",
    "        out = model[layer]\n",
    "        S = sess.run(out)\n",
    "        \n",
    "        #Here, G references model[layer_name] and isn't evaluated yet. \n",
    "        #Later in the code, the image G is set as the model input, so that\n",
    "        # when we run the session, this will be the activations drawn from\n",
    "        #the appropriate layer, with G as input.\n",
    "        G = out\n",
    "        \n",
    "        loss_style_layer = layer_style_loss(S, G)\n",
    "        \n",
    "        #Calculate total cost taken over all layers\n",
    "        loss_style += coeff*loss_style_layer\n",
    "    \n",
    "    return loss_style\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total cost calculation\n",
    "\n",
    "def total_cost(loss_content, loss_style, alpha = 5, beta = 20):\n",
    "    \n",
    "    cost = alpha*loss_content + beta*loss_style\n",
    "    \n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre process images\n",
    "def preprocess_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    image=scipy.misc.imresize(image, (image_height, image_width, channels))\n",
    "    image = np.reshape(image, ((1,)+image.shape))\n",
    "    image = image - mean_values\n",
    "    return image\n",
    "\n",
    "#generate noisy image \n",
    "def generate_noise_image(content_image, noise_ratio = 0.4):\n",
    "    \"\"\"\n",
    "    Returns a noise image intermixed with the content image at a certain ratio.\n",
    "    \"\"\"\n",
    "    noise_image = np.random.uniform(\n",
    "            -20, 20,\n",
    "            (1, image_height, image_width, channels)).astype('float32')\n",
    "    # White noise image from the content representation. Take a weighted average\n",
    "    # of the values\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return input_image\n",
    "\n",
    "#initialise output image \n",
    "def save_image(path, image):\n",
    "    image = image + mean_values\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#set as interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#load all images\n",
    "content = preprocess_image(\"japanese_garden.jpg\")\n",
    "style = preprocess_image(\"picasso_selfportrait.jpg\")\n",
    "generated = generate_noise_image(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = vggmodel(\"imagenet-vgg-verydeep-19.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': <tf.Variable 'Variable:0' shape=(1, 600, 800, 3) dtype=float32_ref>, 'conv1_1': <tf.Tensor 'Relu:0' shape=(1, 600, 800, 64) dtype=float32>, 'conv1_2': <tf.Tensor 'Relu_1:0' shape=(1, 600, 800, 64) dtype=float32>, 'avgpool1': <tf.Tensor 'AvgPool:0' shape=(1, 300, 400, 64) dtype=float32>, 'conv2_1': <tf.Tensor 'Relu_2:0' shape=(1, 300, 400, 128) dtype=float32>, 'conv2_2': <tf.Tensor 'Relu_3:0' shape=(1, 300, 400, 128) dtype=float32>, 'avgpool2': <tf.Tensor 'AvgPool_1:0' shape=(1, 150, 200, 128) dtype=float32>, 'conv3_1': <tf.Tensor 'Relu_4:0' shape=(1, 150, 200, 256) dtype=float32>, 'conv3_2': <tf.Tensor 'Relu_5:0' shape=(1, 150, 200, 256) dtype=float32>, 'conv3_3': <tf.Tensor 'Relu_6:0' shape=(1, 150, 200, 256) dtype=float32>, 'conv3_4': <tf.Tensor 'Relu_7:0' shape=(1, 150, 200, 256) dtype=float32>, 'avgpool3': <tf.Tensor 'AvgPool_2:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv4_1': <tf.Tensor 'Relu_8:0' shape=(1, 75, 100, 512) dtype=float32>, 'conv4_2': <tf.Tensor 'Relu_9:0' shape=(1, 75, 100, 512) dtype=float32>, 'conv4_3': <tf.Tensor 'Relu_10:0' shape=(1, 75, 100, 512) dtype=float32>, 'conv4_4': <tf.Tensor 'Relu_11:0' shape=(1, 75, 100, 512) dtype=float32>, 'avgpool4': <tf.Tensor 'AvgPool_3:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv5_1': <tf.Tensor 'Relu_12:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv5_2': <tf.Tensor 'Relu_13:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv5_3': <tf.Tensor 'Relu_14:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv5_4': <tf.Tensor 'Relu_15:0' shape=(1, 38, 50, 512) dtype=float32>, 'avgpool5': <tf.Tensor 'AvgPool_4:0' shape=(1, 19, 25, 512) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(model['input'].assign(content))\n",
    "out = model['conv4_2']\n",
    "C = sess.run(out)\n",
    "\n",
    "G = out\n",
    "cost_content = content_loss(C,G)\n",
    "\n",
    "\n",
    "sess.run(model['input'].assign(style))\n",
    "cost_style = style_loss(model, style_layers)\n",
    "\n",
    "totalCost = total_cost(cost_content, cost_style, alpha= 10, beta=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "train_step = optimizer.minimize(totalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 200):\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "     \n",
    "    for i in range(num_iterations):\n",
    "        sess.run(train_step)\n",
    "        \n",
    "        # Compute the generated image by running the session on the current model['input']\n",
    "        generated_image = sess.run(model['input'])\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i%20 == 0:\n",
    "            Jt, Jc, Js = sess.run([totalCost, cost_content, cost_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "            print(\"====================================================\")\n",
    "            \n",
    "    filename = \"StyledImage.jpg\"\n",
    "    # save current generated image in the \"/output\" directory\n",
    "    save_image(filename, generated_image)\n",
    "    print(\">> FINISHED GENERATING IMAGE \")\n",
    "        \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "total cost = 6136213500.0\n",
      "content cost = 4401.665\n",
      "style cost = 153404240.0\n",
      "====================================================\n",
      "Iteration 20 :\n",
      "total cost = 983500400.0\n",
      "content cost = 16550.568\n",
      "style cost = 24583372.0\n",
      "====================================================\n",
      "Iteration 40 :\n",
      "total cost = 352512740.0\n",
      "content cost = 18081.863\n",
      "style cost = 8808298.0\n",
      "====================================================\n",
      "Iteration 60 :\n",
      "total cost = 205153260.0\n",
      "content cost = 18560.209\n",
      "style cost = 5124191.5\n",
      "====================================================\n",
      "Iteration 80 :\n",
      "total cost = 144282830.0\n",
      "content cost = 18932.188\n",
      "style cost = 3602337.5\n",
      "====================================================\n",
      "Iteration 100 :\n",
      "total cost = 109200390.0\n",
      "content cost = 19248.605\n",
      "style cost = 2725197.5\n",
      "====================================================\n",
      "Iteration 120 :\n",
      "total cost = 86668020.0\n",
      "content cost = 19517.451\n",
      "style cost = 2161821.0\n",
      "====================================================\n",
      "Iteration 140 :\n",
      "total cost = 71263336.0\n",
      "content cost = 19742.031\n",
      "style cost = 1776647.9\n",
      "====================================================\n",
      "Iteration 160 :\n",
      "total cost = 60110144.0\n",
      "content cost = 19932.965\n",
      "style cost = 1497770.4\n",
      "====================================================\n",
      "Iteration 180 :\n",
      "total cost = 51648496.0\n",
      "content cost = 20099.607\n",
      "style cost = 1286187.5\n",
      "====================================================\n",
      ">> FINISHED GENERATING IMAGE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "styled_image = model_nn(sess, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
