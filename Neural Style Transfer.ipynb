{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer : Myelin Foundry Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with importing all relevant packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining standard units\n",
    "\n",
    "* Multiple layers are used for style transfer to make the generated image capture more styled features from the styling image template. This has been found to give a better mix of style and content.\n",
    "* The mean values are the values which were used during the training of VGG19. This is important because the model's performance is sensitive to these values.\n",
    "* All images are rescaled to 800x600 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]\n",
    "\n",
    "mean_values= np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\n",
    "image_width = 800\n",
    "image_height = 600\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining VGG19\n",
    "\n",
    "VGG19 is used as per the author of the original paper. This architecture has been observed to give the most optimal results for this application compared to other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vggmodel(path):\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "        \"\"\"\n",
    "        Return the weights and bias from the VGG model for a given layer.\n",
    "        \"\"\"\n",
    "        wb = vgg_layers[0][layer][0][0][2]\n",
    "        W = wb[0][0]\n",
    "        b = wb[0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "\n",
    "        return W, b\n",
    "\n",
    "    def _relu(conv2d_layer):\n",
    "        \"\"\"\n",
    "        Return the RELU function wrapped over a TensorFlow layer. Expects a\n",
    "        Conv2d layer input.\n",
    "        \"\"\"\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D + RELU layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "        \"\"\"\n",
    "        Return the AveragePooling layer.\n",
    "        \"\"\"\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Constructs the graph model.\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, image_height, image_width, channels)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Content Loss Function\n",
    "\n",
    "L2 Norm is taken between the vectors of the content image and generated image to calculate loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Content loss function\n",
    "\n",
    "def content_loss(C,G):\n",
    "    #C is activation from set layer for content image \n",
    "    #G is activation from set layer for generated image\n",
    "    \n",
    "    #Get dimensions of Generated image for reshaping\n",
    "    m, H, W, n_C = G.get_shape().as_list()\n",
    "    \n",
    "    #unroll image to vectors for similarity matrix\n",
    "    C_tensor = tf.reshape(C,[n_C, H*W])\n",
    "    G_tensor = tf.reshape(G,[n_C, H*W]) \n",
    "    \n",
    "    #compute cost and normalise it \n",
    "    loss_content = (tf.reduce_sum(tf.square(tf.subtract(C_tensor, G_tensor))))/(4*H*W*n_C)\n",
    "\n",
    "    return loss_content\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Style Loss Function \n",
    "\n",
    "This step consists of several substeps i.e.\n",
    "* Computing Gram Matrix\n",
    "* Computing Single Layer Loss (Again based on L2 norm)\n",
    "* Computing Multi Layer Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Gram matrix computation\n",
    "def gram_matrix(A):\n",
    "    \n",
    "    gram = tf.matmul(A, tf.transpose(A))\n",
    "    return gram \n",
    "\n",
    "\n",
    "#Define Single Layer loss\n",
    "def layer_style_loss(S, G):\n",
    "    #S is activation from set layer for style image \n",
    "    #G is activation from set layer for generated image\n",
    "    \n",
    "    #Get dimensions of Generated image for reshaping\n",
    "    m, H, W, n_C = G.get_shape().as_list()\n",
    "    \n",
    "    #unroll image to vectors to get gram matrix computation\n",
    "    S_tensor = tf.transpose(tf.reshape(S,[ H*W,n_C]))\n",
    "    G_tensor = tf.transpose(tf.reshape(G,[ H*W,n_C]))\n",
    "    \n",
    "    #Getting gram matrices \n",
    "    S_gram = gram_matrix(S_tensor)\n",
    "    G_gram = gram_matrix(G_tensor)\n",
    "    \n",
    "    #computing cost and normalising it\n",
    "    loss_style = (tf.reduce_sum(tf.square(tf.subtract(G_gram, S_gram))))/(4*n_C**2*(H*W)**2)\n",
    "    \n",
    "    return loss_style \n",
    "    \n",
    "#Define Multi Layer loss\n",
    "def style_loss(model, layers):\n",
    "    #Taking style across various layers with its corresponding weights\n",
    "    #which is provided by the list of ```layers```\n",
    "    \n",
    "    loss_style = 0\n",
    "    \n",
    "    for layer, coeff in layers:\n",
    "        \n",
    "        #extracting output from a particular layer\n",
    "        out = model[layer]\n",
    "        S = sess.run(out)\n",
    "        \n",
    "        #Here, G references model[layer_name] and isn't evaluated yet. \n",
    "        #Later in the code, the image G is set as the model input, so that\n",
    "        # when we run the session, this will be the activations drawn from\n",
    "        #the appropriate layer, with G as input.\n",
    "        G = out\n",
    "        \n",
    "        loss_style_layer = layer_style_loss(S, G)\n",
    "        \n",
    "        #Calculate total cost taken over all layers\n",
    "        loss_style += coeff*loss_style_layer\n",
    "    \n",
    "    return loss_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Total Loss\n",
    "\n",
    "The total loss is calculated based on the cumulative effect of the content loss and style loss factors. The total loss is defined by two hyperparameters : alpha and beta, which decide the weightage given to the cost functions of content and style ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total cost calculation\n",
    "\n",
    "def total_cost(loss_content, loss_style, alpha = 5, beta = 20):\n",
    "    \n",
    "    cost = alpha*loss_content + beta*loss_style\n",
    "    \n",
    "    return cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Images\n",
    "\n",
    "We pre process the input images, synthesize a general output image and define a function for saving the styled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre process images\n",
    "def preprocess_image(path):\n",
    "    image = scipy.misc.imread(path)\n",
    "    image=scipy.misc.imresize(image, (image_height, image_width, channels))\n",
    "    image = np.reshape(image, ((1,)+image.shape))\n",
    "    image = image - mean_values\n",
    "    return image\n",
    "\n",
    "#generate noisy image \n",
    "def generate_noise_image(content_image, noise_ratio = 0.4):\n",
    "    #returns a noise image intermixed with the content image at a certain ratio.\n",
    "    noise_image = np.random.uniform(-20, 20,\n",
    "            (1, image_height, image_width, channels)).astype('float32')\n",
    "    # White noise image from the content representation. Take a weighted average\n",
    "    # of the values\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return input_image\n",
    "\n",
    "#initialise output image \n",
    "def save_image(path, image):\n",
    "    image = image + mean_values\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#set as interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#load all images\n",
    "content = preprocess_image(\"japanese_garden.jpg\")\n",
    "style = preprocess_image(\"picasso_selfportrait.jpg\")\n",
    "generated = generate_noise_image(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the model\n",
    "model = vggmodel(\"imagenet-vgg-verydeep-19.mat\")\n",
    "\n",
    "#print(model) #Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(model['input'].assign(content))\n",
    "out = model['conv4_2']\n",
    "#get the content image from the required layer\n",
    "C = sess.run(out)\n",
    "\n",
    "#get the generated image from the same layer\n",
    "G = out\n",
    "\n",
    "#Calculate the content loss \n",
    "cost_content = content_loss(C,G)\n",
    "\n",
    "#get the styled image from the same layer\n",
    "sess.run(model['input'].assign(style))\n",
    "\n",
    "#Calculate style cost\n",
    "cost_style = style_loss(model, style_layers)\n",
    "\n",
    "#Calculate total cost\n",
    "totalCost = total_cost(cost_content, cost_style, alpha= 10, beta=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define optimizer for optimizing the total loss function and define train_step\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "train_step = optimizer.minimize(totalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_min(sess, input_image, num_iterations = 200):\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "     \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        #run session to minimize total cost\n",
    "        sess.run(train_step)\n",
    "        \n",
    "        # Compute the generated image by running the session on the current model['input']\n",
    "        generated_image = sess.run(model['input'])\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i%20 == 0:\n",
    "            Jt, Jc, Js = sess.run([totalCost, cost_content, cost_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "            print(\"====================================================\")\n",
    "            \n",
    "    filename = \"StyledImage.jpg\"\n",
    "    save_image(filename, generated_image)\n",
    "    print(\">> FINISHED GENERATING IMAGE \")\n",
    "        \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 20 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 40 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 60 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 80 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 100 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 120 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 140 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 160 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      "Iteration 180 :\n",
      "total cost = 7926048000.0\n",
      "content cost = 3269.9355\n",
      "style cost = 198150370.0\n",
      "====================================================\n",
      ">> FINISHED GENERATING IMAGE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "styled_image = cost_min(sess, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
